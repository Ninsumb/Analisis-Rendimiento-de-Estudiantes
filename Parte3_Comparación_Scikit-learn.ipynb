{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Parte 3: Comparación**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Punto 1:** Implementación en scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como pide la consigna, primero pruebo implementando en scikit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntaje del conjunto de entrenamiento: 0.921008\n",
      "Puntaje del conjunto de prueba: 0.922249\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "df = pd.read_csv('Factores_de_Buen_Rendimiento_en_Estudiantes_actualizado.csv', delimiter=\",\")\n",
    "\n",
    "X = df.values[:, :-1]\n",
    "Y = df.values[:, -1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=1/3)\n",
    "\n",
    "nn = MLPClassifier(solver='sgd',\n",
    "                   hidden_layer_sizes=(6,4),\n",
    "                   activation='relu',\n",
    "                   max_iter=100_000,\n",
    "                   learning_rate_init=.05)\n",
    "\n",
    "nn.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Puntaje del conjunto de entrenamiento: %f\" % nn.score(X_train, Y_train))\n",
    "print(\"Puntaje del conjunto de prueba: %f\" % nn.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntaje del conjunto de entrenamiento: 0.921252\n",
      "Puntaje del conjunto de prueba: 0.920782\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "df = pd.read_csv('Factores_de_Buen_Rendimiento_en_Estudiantes_actualizado.csv', delimiter=\",\")\n",
    "\n",
    "X = df.values[:, :-1]\n",
    "Y = df.values[:, -1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=1/3)\n",
    "\n",
    "nn = MLPClassifier(solver='sgd',\n",
    "                   hidden_layer_sizes=(6,4),\n",
    "                   activation='relu',\n",
    "                   max_iter=10_000,\n",
    "                   learning_rate_init=.05)\n",
    "\n",
    "nn.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Puntaje del conjunto de entrenamiento: %f\" % nn.score(X_train, Y_train))\n",
    "print(\"Puntaje del conjunto de prueba: %f\" % nn.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como probe en mi red neuronal \"hecha a mano\", con 100000 iteraciones y L = 0.05, obtengo un resultado muy parecido. El puntaje de entrenamiento en mi red neuronal es 0.921496698459281, así que me acerco bastante. El de prueba en cambio es  0.9168704156479217, pero sigue siendo cercano a mi puntaje de acá. Igualmente, Scikit-Learn tiene una desventaja para mi modelo. Entre los parámetros disponibles para \"activation\", con lo que defino la función de activación, no está Leaky-ReLU...  Si bien puedo dejarlo así, voy a probar con otra libreria de aprendizaje autómatico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la comparación con TensorFlow voy a usar menos iteraciones (10.000 en concreto), que también me daban un accuracy de 0.92 con L = 0.05, para reducir el costo computacional y ahorrar tiempo (tarda muchísimo tiempo en procesar las 100000 iteraciones). También agregué arriba un bloque de codigo para evaluar el accuracy en sklearn con 10000 iters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "df = pd.read_csv('Factores_de_Buen_Rendimiento_en_Estudiantes_actualizado.csv', delimiter=\",\")\n",
    "\n",
    "X = df.values[:, :-1]\n",
    "Y = df.values[:, -1]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=1/3)\n",
    "\n",
    "# Crear el modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(6))  # Capa de entrada\n",
    "model.add(LeakyReLU(alpha=0.1))     # Función de activación Leaky ReLU\n",
    "model.add(Dense(4))                 # Capa oculta\n",
    "model.add(LeakyReLU(alpha=0.1))     # Función de activación Leaky ReLU\n",
    "model.add(Dense(1, activation='sigmoid'))  # Capa de salida\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate = 0.05)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, epochs=10000, batch_size = 1000, verbose=1) #Batch_size predeterminado = 32 \n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veo que termino obteniendo un accuracy de 0.92 al final, también muy cerca del puntaje de mi red. Y por problemas con el ipynb y github, voy a dejar adjunta en la carpeta del trabajo la captura del resultado final. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  **Punto 2:** Comparación de Rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como analicé en el punto anterior, obtuve en todas las pruebas puntajes muy similares. Las diferencias claras de rendimiento son el tiempo que tarda Sklearn (y tensorflow) en procesar los datos y entrenar el modelo. En el caso de TensorFlow, tarda muchísimo en hacer todas las iteraciones, mientras que a Sklearn no le cuesta. Sklearn tiene la mayor ventaja en cuanto a tiempo de ejecución, ya que a mi red también le cuesta hacer las 100000 iteraciones que la libreria de aprendizaje hace en 0,7 segundos. Igualmente, este tiempo es causalmente el menor que obtuve, a veces puede tardar un poco más con los mismos parámetros. Parece que eso ya es algo que depende de factores externos. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
